{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:57:50.242915Z",
     "start_time": "2019-12-06T16:57:24.122720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import jieba  \n",
    "import xlrd\n",
    "import xlwt \n",
    "from collections import Counter\n",
    "import re\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2#卡方检验——特征筛选\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "os.chdir(r\"C:\\Users\\Administrator\\OneDrive\\课件\\自然语言处理\\分类\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:57:50.454259Z",
     "start_time": "2019-12-06T16:57:50.253851Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('10000_hotel.csv', encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:57:50.503907Z",
     "start_time": "2019-12-06T16:57:50.478006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>首先感觉不像大酒店,应该属于公寓式酒店,房间很小,明显是住宅公寓改装的.其次门童的服务不好,...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>房间和走廊里味道很重，楼外下面马路上的声音很吵，早上隔壁的电视机的声音听的很清楚，可以当闹钟...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>虽然预定比较方便，但是宾馆的对顾客的关怀不足，房间冷得让人睡不着觉服务人员还说暖和的！！！宾...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>酒店位置不是很理想，去金元购物中心还是蛮近的，大约10分钟车程，我入住的是448的房间，正赶...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>真不知道之前的点评是怎么得出来的，还以为会是一个不错的酒店，谁知完全不是那么回事。首先酒店没...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>号称平遥最高级的四星酒店，实际只是二星半的硬件，二十年前国营招待所的服务，差极了。可能因为住...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>根本就是一个招待所！亏的还能上携程网推荐！真是丢死人的脸了。前台（姑且升格称其为前台）服务态...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>酒店的管理不专业，服务非常差，房间的空调不足，冬天的被子象夏天被，晚上住宿要用自己的羽绒衣防寒。</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>订了商务大床间，可惜房间小的可怜！床和写字台之间太紧，基本上不能转身。更无法忍受的是房间卫生...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>非常糟糕的酒店,住了1天,停电两次,酒店装修的材料很劣质,甲醛的味道让人睁不开眼睛.地理位置...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>据说是太仓最好的酒店，作为一个5星级的酒店让我很失望。房间小而简单并且陈旧，最多也只是个3星...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>位置在4叉路口，有高架桥（高架桥上车少竟然有摩托车！）安吉有许多改装过的三轮“汽车”，发出拖...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>是第二次入住，因为离客户很近，图个方便。先说第一次的入住，空调不冷搞得房间像桑拿房一样，我把...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>我们要了两间标准大床房在9楼，每间418元，入住时发现房间设施极差，家具桌椅好像学校里学生用...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>我们是5月1日通过携程网入住的，条件是太差了，根本达不到四星级的标准，所有的东西都很陈旧，卫...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>服务不好！服务意识非常烂。订的双早房间，结果早餐只给了1张，吃早餐时被告知自己去找前台，态度...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>酒店服务不好，服务员态度生硬，特别是酒店物品管理方面，物品的清点不到位，我明明没有用房间内的...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>刚为朋友29号预定的北方担心过，不料30号结房时，前台问我朋友房间的有线电视摇控器不见了，后...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>房间设施相当差，马桶圈居然小了一大圈，浴缸的水直接排到卫生间的下水道，洗个澡弄的卫生间里全是...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>酒店一般，最受不了的是骚扰电话，一晚上能响4～5回，而且每晚都会打来，只真对单身男客，信息非...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>大年初一入住的，酒店的装修不错，可是前台服务就一位男生，态度很冷淡，感觉不希望我们入住似的，...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>住过这么多酒店，从来没有住过这么小旧脏老臭的“大床房”！一进门就被一股臭味熏了出来，开了一天...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>酒店确实是旧了，房间家具有些都不能用了，连床头灯都坏了，毛巾也感觉脏脏的，房间的隔音效果也特...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@次在此住了9晚上...房gm大...s有蚊子..隔音太差...向可否能o蚊香...酒店台居...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>说老实话，我还没有见过这么差的酒店呢！前台服务人员素质极低，还给我信用卡用扔的方式，打电话给...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>说老实话，我还没有见过这么差的酒店呢！前台服务人员素质极低，还给我信用卡用扔的方式，打电话给...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>春节期间入住，感觉硬件环境还马马虎虎，但是酒店服务太差，名为温泉度假村，但是对住店客人没有任...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>酒店的设施和服务与描述及其不相符硬件最多2.5星水平，卫生状况一般，床单上有洗不掉的污渍，床...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>我很少做酒店点评，但这个酒店确实是我近年住的最差的酒店。地方非常不好找，大部份的士司机都找不...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>酒店从价格来讲还算便宜。但前台有特价房68，而在携程只能顶到98的，这一点我接受不了。酒店服...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>地理位置不错,自己开车去还是很方便的,房间幽雅舒适,非常干净!价格也比较合理,比我住的3星的...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>位置离市区比较远。除了环境好以外，哪里都不象五星级酒店。房间还不错，空间很大，但感觉设施一般...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>交通方便,市中心,房间比较有意思,不同楼层有不同的装修风格,我住了三次,次次房间都不一样,有...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>性价比很高。虽然是没有挂牌按照四星标准建造，但是非常不错。房间很大设备齐全。酒店所处位置交通...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>如果小不是问题，如果你能接受房价比较压抑，那么曼哈顿真是不错的选择。。。</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>距拱北关口步行15分钟可以到达，很方便，酒店豪华标准间太小，卫生间设施有点旧，但是热水充足，...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>服务态度不错,遇到的每一位服务人员都能主动问好,老外很多,这个酒店可能有不同层面的客房,下次...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>不错的一家酒店，服务人员都很有礼貌。住在二楼，虽然是木质结构，不过周围还算是比较安静的。早餐...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>晚上10点至凌晨4点之间骚扰电话太多，常常无法入睡，给总台反映过，但是没有起到作用！</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>清明小长假过去的，和晓起的农家标间比较，这个价格和设施还是比较有竞争力的。不远处有锦江之星，...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>酒店和房间的基本设施都还行,就是服务还需跟上</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>服务态度很不错，呵呵，而且离我们去的地方非常近，非常方便，环境也很好，希望下次还可以住那里</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>这个价位住到这样的房间对我来说是惊喜，订的商务大床房，很夸敞舒适，房间最里面顺着靠窗的地方走...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>硬件设施不错，还有赠送的水果，早餐比较丰富，不足的是隔音效果差，晚上能清楚地听见隔壁的谈话声...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>入住的是贵宾楼，房间面积还算大，感觉硬件和服务都还不错。缺点是隔音效果不是很好，住隔壁的同事...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>酒店前台效率比较低，我们在CHECK-IN的时候，有另外一个老外在CHECK-OUT，那两个...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>还不错，服务员的响应速度有点慢。住的房间空调声音有点响，里面好像有异物，当啷当啷的。</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>不错的酒店~~相当的安静~~</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>来苏州好多次了，基本上都住在这家酒店。给我的感觉非常好，房间很干净，设施也很全，各种用品也很...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>早餐食物相当一般，跟其服务水准不相符，希望进一步改进。</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>卫生总的是挺好～细节上，有点点瑕疵．我很喜欢房间的布局～周围的环境真的很安静，在旅途劳顿后睡...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>预定的曙光别墅间，入住后发现房间很小，好像还很潮湿，最烦心的是发现了老鼠。后来加了钱换了饭店...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>非常别致的一家酒店，设计很独特。地理位置有点偏，但酒店有班车也挺方便的。下次还会住。很喜欢：―）</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>不是特别满意位置不太好但价格比较合理去了才知道，他是3星级的，外表有点旧旧的</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>感觉也不算５星，还不如协议的好呢．看来只有我们协议稍微满意点</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.前台服务人员很有礼貌与热情。2.定的是大床房，房间空间和格局不错，就是地毯有点脏，冰箱的...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>酒店的服务是不错的，但是硬件不够五星标准，什么都要再收费。晚上的自助餐很值，酒店去市中心的巴...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>服务很好!干净舒适~招待也很热心~!餐饮也很不错~!第一次住酒店~感觉很好!~下次还会来的~!</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>酒店设计有特色，房间很舒服亦很美，位置于南门很方便出入，而且又有得免费上网。前台服务员不错，...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>大堂的服务员很热情,有宾至如归的感觉。入住的商务客房，除了有电脑，还有多功能传真机，可以在房...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment sentiment\n",
       "0     首先感觉不像大酒店,应该属于公寓式酒店,房间很小,明显是住宅公寓改装的.其次门童的服务不好,...       neg\n",
       "1     房间和走廊里味道很重，楼外下面马路上的声音很吵，早上隔壁的电视机的声音听的很清楚，可以当闹钟...       neg\n",
       "2     虽然预定比较方便，但是宾馆的对顾客的关怀不足，房间冷得让人睡不着觉服务人员还说暖和的！！！宾...       neg\n",
       "3     酒店位置不是很理想，去金元购物中心还是蛮近的，大约10分钟车程，我入住的是448的房间，正赶...       neg\n",
       "4     真不知道之前的点评是怎么得出来的，还以为会是一个不错的酒店，谁知完全不是那么回事。首先酒店没...       neg\n",
       "5     号称平遥最高级的四星酒店，实际只是二星半的硬件，二十年前国营招待所的服务，差极了。可能因为住...       neg\n",
       "6     根本就是一个招待所！亏的还能上携程网推荐！真是丢死人的脸了。前台（姑且升格称其为前台）服务态...       neg\n",
       "7      酒店的管理不专业，服务非常差，房间的空调不足，冬天的被子象夏天被，晚上住宿要用自己的羽绒衣防寒。       neg\n",
       "8     订了商务大床间，可惜房间小的可怜！床和写字台之间太紧，基本上不能转身。更无法忍受的是房间卫生...       neg\n",
       "9     非常糟糕的酒店,住了1天,停电两次,酒店装修的材料很劣质,甲醛的味道让人睁不开眼睛.地理位置...       neg\n",
       "10    据说是太仓最好的酒店，作为一个5星级的酒店让我很失望。房间小而简单并且陈旧，最多也只是个3星...       neg\n",
       "11    位置在4叉路口，有高架桥（高架桥上车少竟然有摩托车！）安吉有许多改装过的三轮“汽车”，发出拖...       neg\n",
       "12    是第二次入住，因为离客户很近，图个方便。先说第一次的入住，空调不冷搞得房间像桑拿房一样，我把...       neg\n",
       "13    我们要了两间标准大床房在9楼，每间418元，入住时发现房间设施极差，家具桌椅好像学校里学生用...       neg\n",
       "14    我们是5月1日通过携程网入住的，条件是太差了，根本达不到四星级的标准，所有的东西都很陈旧，卫...       neg\n",
       "15    服务不好！服务意识非常烂。订的双早房间，结果早餐只给了1张，吃早餐时被告知自己去找前台，态度...       neg\n",
       "16    酒店服务不好，服务员态度生硬，特别是酒店物品管理方面，物品的清点不到位，我明明没有用房间内的...       neg\n",
       "17    刚为朋友29号预定的北方担心过，不料30号结房时，前台问我朋友房间的有线电视摇控器不见了，后...       neg\n",
       "18    房间设施相当差，马桶圈居然小了一大圈，浴缸的水直接排到卫生间的下水道，洗个澡弄的卫生间里全是...       neg\n",
       "19    酒店一般，最受不了的是骚扰电话，一晚上能响4～5回，而且每晚都会打来，只真对单身男客，信息非...       neg\n",
       "20    大年初一入住的，酒店的装修不错，可是前台服务就一位男生，态度很冷淡，感觉不希望我们入住似的，...       neg\n",
       "21    住过这么多酒店，从来没有住过这么小旧脏老臭的“大床房”！一进门就被一股臭味熏了出来，开了一天...       neg\n",
       "22    酒店确实是旧了，房间家具有些都不能用了，连床头灯都坏了，毛巾也感觉脏脏的，房间的隔音效果也特...       neg\n",
       "23    @次在此住了9晚上...房gm大...s有蚊子..隔音太差...向可否能o蚊香...酒店台居...       neg\n",
       "24    说老实话，我还没有见过这么差的酒店呢！前台服务人员素质极低，还给我信用卡用扔的方式，打电话给...       neg\n",
       "25    说老实话，我还没有见过这么差的酒店呢！前台服务人员素质极低，还给我信用卡用扔的方式，打电话给...       neg\n",
       "26    春节期间入住，感觉硬件环境还马马虎虎，但是酒店服务太差，名为温泉度假村，但是对住店客人没有任...       neg\n",
       "27    酒店的设施和服务与描述及其不相符硬件最多2.5星水平，卫生状况一般，床单上有洗不掉的污渍，床...       neg\n",
       "28    我很少做酒店点评，但这个酒店确实是我近年住的最差的酒店。地方非常不好找，大部份的士司机都找不...       neg\n",
       "29    酒店从价格来讲还算便宜。但前台有特价房68，而在携程只能顶到98的，这一点我接受不了。酒店服...       neg\n",
       "...                                                 ...       ...\n",
       "9970  地理位置不错,自己开车去还是很方便的,房间幽雅舒适,非常干净!价格也比较合理,比我住的3星的...       pos\n",
       "9971  位置离市区比较远。除了环境好以外，哪里都不象五星级酒店。房间还不错，空间很大，但感觉设施一般...       pos\n",
       "9972  交通方便,市中心,房间比较有意思,不同楼层有不同的装修风格,我住了三次,次次房间都不一样,有...       pos\n",
       "9973  性价比很高。虽然是没有挂牌按照四星标准建造，但是非常不错。房间很大设备齐全。酒店所处位置交通...       pos\n",
       "9974               如果小不是问题，如果你能接受房价比较压抑，那么曼哈顿真是不错的选择。。。       pos\n",
       "9975  距拱北关口步行15分钟可以到达，很方便，酒店豪华标准间太小，卫生间设施有点旧，但是热水充足，...       pos\n",
       "9976  服务态度不错,遇到的每一位服务人员都能主动问好,老外很多,这个酒店可能有不同层面的客房,下次...       pos\n",
       "9977  不错的一家酒店，服务人员都很有礼貌。住在二楼，虽然是木质结构，不过周围还算是比较安静的。早餐...       pos\n",
       "9978         晚上10点至凌晨4点之间骚扰电话太多，常常无法入睡，给总台反映过，但是没有起到作用！       pos\n",
       "9979  清明小长假过去的，和晓起的农家标间比较，这个价格和设施还是比较有竞争力的。不远处有锦江之星，...       pos\n",
       "9980                             酒店和房间的基本设施都还行,就是服务还需跟上       pos\n",
       "9981      服务态度很不错，呵呵，而且离我们去的地方非常近，非常方便，环境也很好，希望下次还可以住那里       pos\n",
       "9982  这个价位住到这样的房间对我来说是惊喜，订的商务大床房，很夸敞舒适，房间最里面顺着靠窗的地方走...       pos\n",
       "9983  硬件设施不错，还有赠送的水果，早餐比较丰富，不足的是隔音效果差，晚上能清楚地听见隔壁的谈话声...       pos\n",
       "9984  入住的是贵宾楼，房间面积还算大，感觉硬件和服务都还不错。缺点是隔音效果不是很好，住隔壁的同事...       pos\n",
       "9985  酒店前台效率比较低，我们在CHECK-IN的时候，有另外一个老外在CHECK-OUT，那两个...       pos\n",
       "9986         还不错，服务员的响应速度有点慢。住的房间空调声音有点响，里面好像有异物，当啷当啷的。       pos\n",
       "9987                                     不错的酒店~~相当的安静~~       pos\n",
       "9988  来苏州好多次了，基本上都住在这家酒店。给我的感觉非常好，房间很干净，设施也很全，各种用品也很...       pos\n",
       "9989                        早餐食物相当一般，跟其服务水准不相符，希望进一步改进。       pos\n",
       "9990  卫生总的是挺好～细节上，有点点瑕疵．我很喜欢房间的布局～周围的环境真的很安静，在旅途劳顿后睡...       pos\n",
       "9991  预定的曙光别墅间，入住后发现房间很小，好像还很潮湿，最烦心的是发现了老鼠。后来加了钱换了饭店...       pos\n",
       "9992   非常别致的一家酒店，设计很独特。地理位置有点偏，但酒店有班车也挺方便的。下次还会住。很喜欢：―）       pos\n",
       "9993             不是特别满意位置不太好但价格比较合理去了才知道，他是3星级的，外表有点旧旧的       pos\n",
       "9994                     感觉也不算５星，还不如协议的好呢．看来只有我们协议稍微满意点       pos\n",
       "9995  1.前台服务人员很有礼貌与热情。2.定的是大床房，房间空间和格局不错，就是地毯有点脏，冰箱的...       pos\n",
       "9996  酒店的服务是不错的，但是硬件不够五星标准，什么都要再收费。晚上的自助餐很值，酒店去市中心的巴...       pos\n",
       "9997    服务很好!干净舒适~招待也很热心~!餐饮也很不错~!第一次住酒店~感觉很好!~下次还会来的~!       pos\n",
       "9998  酒店设计有特色，房间很舒服亦很美，位置于南门很方便出入，而且又有得免费上网。前台服务员不错，...       pos\n",
       "9999  大堂的服务员很热情,有宾至如归的感觉。入住的商务客房，除了有电脑，还有多功能传真机，可以在房...       pos\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:57:50.540404Z",
     "start_time": "2019-12-06T16:57:50.528812Z"
    }
   },
   "outputs": [],
   "source": [
    "def stopwordslist(filepath):  \n",
    "    stopwords = [line.strip() for line in open(filepath, 'r').readlines()]  \n",
    "    return stopwords  \n",
    "def classify_words(word_dict):  \n",
    "    \"\"\"词语分类,找出情感词、否定词、程度副词\"\"\"  \n",
    "    # 读取情感字典文件  \n",
    "    sen_word = dict()  \n",
    "    not_word = dict()  \n",
    "    degree_word = dict()  \n",
    "    # 分类  \n",
    "    for word in word_dict.keys(): \n",
    "        if word in sen_dict.keys() and word not in not_word_list and word not in degree_dic.keys():  \n",
    "            # 找出分词结果中在情感字典中的词  \n",
    "            sen_word[word_dict[word]] = sen_dict[word]  \n",
    "        elif word+'\\n' in not_word_list and word not in degree_dic.keys():  \n",
    "            # 分词结果中在否定词列表中的词  \n",
    "            not_word[word_dict[word]] = -1 \n",
    "        elif word in degree_dic.keys():  \n",
    "            # 分词结果中在程度副词中的词  \n",
    "            degree_word[word_dict[word]] = degree_dic[word]   \n",
    "    # 将分类结果返回  \n",
    "    sen_num=len(sen_word)    \n",
    "    degree_num=len(degree_word) \n",
    "    not_num=len(not_word)\n",
    "    return sen_word,not_word,degree_word,sen_num,not_num,degree_num \n",
    " \n",
    "def list_to_dict(word_list):  \n",
    "    \"\"\"将分词后的列表转为字典，key为单词，value为单词在列表中的索引，索引相当于词语在文档中出现的位置\"\"\"  \n",
    "    data = {}  \n",
    "    for x in range(0, len(word_list)):  \n",
    "        data[word_list[x]] = x  \n",
    "    return data  \n",
    "  \n",
    "def get_init_weight(sen_word, not_word,degree_word):  \n",
    "    # 权重初始化为1  \n",
    "    W = 1  \n",
    "    # 将情感字典的key转为list  \n",
    "    sen_word_index_list = list(sen_word.keys())  \n",
    "    if len(sen_word_index_list) == 0:  \n",
    "        return W  \n",
    "    # 获取第一个情感词的下标，遍历从0到此位置之间的所有词，找出程度词和否定词  \n",
    "    for i in range(0, sen_word_index_list[0]):  \n",
    "        if i in not_word.keys():  \n",
    "            W *= -1  \n",
    "        elif i in degree_word.keys():  \n",
    "             # 更新权重，如果有程度副词，分值乘以程度副词的程度分值  \n",
    "            W *= float(degree_word[i])  \n",
    "    return W    \n",
    "  \n",
    "def socre_sentiment(sen_word, not_word,degree_word,seg_result): #degree_word  \n",
    "    \"\"\"计算得分\"\"\"  \n",
    "    # 权重初始化为1  \n",
    "    num=0;\n",
    "    W = 1  \n",
    "    score = 0  \n",
    "    # 情感词下标初始化  \n",
    "    sentiment_index = -1  \n",
    "    # 情感词的位置下标集合  \n",
    "    sentiment_index_list = list(sen_word.keys())  \n",
    "    # 遍历分词结果(遍历分词结果是为了定位两个情感词之间的程度副词和否定词)  \n",
    "    for i in range(0, len(seg_result)):  \n",
    "        # 如果是情感词（根据下标是否在情感词分类结果中判断）  \n",
    "        if i in sen_word.keys():  \n",
    "            num=num+1;\n",
    "            # 权重*情感词得分  \n",
    "            score=score+ W * float(sen_word[i])  \n",
    "            # 情感词下标加1，获取下一个情感词的位置  \n",
    "            sentiment_index += 1  \n",
    "            if sentiment_index < len(sentiment_index_list) - 1:  \n",
    "                # 判断当前的情感词与下一个情感词之间是否有程度副词或否定词  \n",
    "                for j in range(sentiment_index_list[sentiment_index], sentiment_index_list[sentiment_index + 1]):  \n",
    "                    # 更新权重，如果有否定词，取反  \n",
    "                    if j in not_word.keys():  \n",
    "                        W = W*-1  \n",
    "                    elif j in degree_word.keys():  \n",
    "                        # 更新权重，如果有程度副词，分值变成程度副词的程度分值  \n",
    "                        W *= float(degree_word[j])\n",
    "                        W *= float(degree_word[j])\n",
    "        # 定位到下一个情感词  \n",
    "        if sentiment_index < len(sentiment_index_list) - 1:  \n",
    "            i = sentiment_index_list[sentiment_index + 1]\n",
    "        if num!=0:\n",
    "            #考虑到了评论长度因素\n",
    "            score=score/num  \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:57:50.822337Z",
     "start_time": "2019-12-06T16:57:50.557914Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "sen_file = open(r'BosonNLP_sentiment_score.txt', 'r', encoding='utf-8')  \n",
    "# 获取字典文件内容  \n",
    "sen_list = sen_file.readlines()  \n",
    "# 创建情感字典  \n",
    "sen_dict = defaultdict()  \n",
    "# 读取字典文件每一行内容，将其转换为字典对象，key为情感词，value为对应的分值\n",
    "for s in sen_list:  \n",
    "    # 每一行内容根据空格分割，索引0是情感词，索引01是情感分值\n",
    "    if (len(s.split(' '))==2):\n",
    "        sen_dict[s.split(' ')[0]] = s.split(' ')[1]  \n",
    "\n",
    "# 读取否定词文件  \n",
    "not_word_file = open(r'notDic.txt', 'r+', encoding='utf-8-sig')  \n",
    "# 由于否定词只有词，没有分值，使用list即可  \n",
    "not_word_dict = defaultdict()  \n",
    "not_word_list = not_word_file.readlines() \n",
    "\n",
    "#读取程度副词文件  \n",
    "degree_file = open(r'degree.txt','r+')  \n",
    "degree_list = degree_file.readlines()  \n",
    "degree_dic = defaultdict()  \n",
    "#程度副词与情感词处理方式一样，转为程度副词字典对象，key为程度副词，value为对应的程度值  \n",
    "for d in degree_list:  \n",
    "    degree_dic[d.split(',')[0]] = d.split(',')[1]  \n",
    "\n",
    "sen_file.close()  \n",
    "degree_file.close()  \n",
    "not_word_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:57:50.932807Z",
     "start_time": "2019-12-06T16:57:50.925814Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = stopwordslist(r'stopword.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#情感计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:58:20.694553Z",
     "start_time": "2019-12-06T16:57:51.038061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe43539009341de9c02220d347047d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.887 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data =xlrd.open_workbook(r'10000_hotel.xlsx')\n",
    "file = xlwt.Workbook()\n",
    "table_w = file.add_sheet('fenci',cell_overwrite_ok=True)\n",
    "table = data.sheet_by_index(0) #第一个表格\n",
    "nrows = table.nrows #表格的行数\n",
    "ncols = table.ncols #表格的列数 这里只有一列\n",
    "\n",
    "for i in tqdm_notebook(range(table.nrows)):\n",
    "    num=0;\n",
    "    #seg_list = jieba.cut(table.row(i)[0].value) #获取第1列的值 索引号不管行还是列还是表都是从0开始\n",
    "    outstr='' \n",
    "    sen_num,not_num,degree_num,score = 0,0,0,0\n",
    "     # 3.计算得分  \n",
    "    if i > 0 :\n",
    "        table_w.write(i,0,table.row(i)[0].value) \n",
    "        for n in re.split('，|。|！|？', table.row(i)[0].value):  #获取第1列的值 索引号不管行还是列还是表都是从0开始\n",
    "            #print(n)\n",
    "            seg_list =  jieba.lcut(n)\n",
    "            seg_result = [] \n",
    "            for word in seg_list:  #在分词的里面\n",
    "                if word not in stopwords:  \n",
    "                    if word != '\\t':  \n",
    "                        outstr += word  \n",
    "                        outstr += \" \"\n",
    "                        seg_result.append(word)\n",
    "            #print(seg_result)\n",
    "            sen_word, not_word,degree_word,sen_num_,not_num_,degree_num_= classify_words(list_to_dict(seg_result))\n",
    "            sen_num += sen_num_\n",
    "            not_num += not_num_\n",
    "            degree_num += degree_num_\n",
    "            score+=socre_sentiment(sen_word, not_word, degree_word, seg_result)\n",
    "        table_w.write(i,1,outstr) \n",
    "        table_w.write(i,2,score)\n",
    "        table_w.write(i,3,not_num)\n",
    "        table_w.write(i,4,degree_num)\n",
    "        table_w.write(i,5,sen_num)\n",
    "    else :\n",
    "        table_w.write(0,0,\"原词\") #第一行第一列写入“原词”\n",
    "        table_w.write(0,1,\"分词结果\") \n",
    "        table_w.write(0,2,\"score\") \n",
    "        table_w.write(0,3,\"num1\")\n",
    "        table_w.write(0,4,\"num2\")\n",
    "        table_w.write(0,5,\"num3\")\n",
    "file.save(r'result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:58:21.207151Z",
     "start_time": "2019-12-06T16:58:20.795235Z"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('10000_hotel.csv', encoding='ansi')['sentiment']\n",
    "le = LabelEncoder() #0-1\n",
    "y=le.fit_transform(y)\n",
    "y = pd.DataFrame(y, columns=['label'])\n",
    "data = pd.read_excel(\"result.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:58:22.180511Z",
     "start_time": "2019-12-06T16:58:21.348737Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 过滤部分特征 cbow\n",
    "token_pattern = u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b'\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 3,\n",
    "               token_pattern=token_pattern,\n",
    "               stop_words=frozenset(stopwords))\n",
    "\n",
    "x_ = data['分词结果']\n",
    "\n",
    "# 文本向量化\n",
    "x = vectorizer.fit_transform(x_.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:58:40.643045Z",
     "start_time": "2019-12-06T16:58:40.125382Z"
    }
   },
   "outputs": [],
   "source": [
    "#降维\n",
    "ch2 = SelectKBest(chi2,k=1000)\n",
    "x_train_ = ch2.fit_transform(x,y)\n",
    "\n",
    "x_train_ = pd.DataFrame(x_train_.toarray())\n",
    "x_train_ = x_train_.set_index(data.index)\n",
    "x = pd.concat([data.iloc[:,2:],x_train_],axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:58:43.445383Z",
     "start_time": "2019-12-06T16:58:43.439046Z"
    }
   },
   "outputs": [],
   "source": [
    "def Lgb_Classifier(train_x, train_y,test_x,test_y, params_lgb=None):\n",
    "    import lightgbm as lgb\n",
    "    lgb_trn = lgb.Dataset(\n",
    "                        data=train_x,\n",
    "                        label=train_y,\n",
    "                        free_raw_data=True)\n",
    "    lgb_val = lgb.Dataset(\n",
    "                        data=test_x,\n",
    "                        label=test_y,\n",
    "                        free_raw_data=True)\n",
    "    if params_lgb==None:\n",
    "        params_lgb = {'boosting_type': 'gbdt','objective': 'binary','save_binary': True,\n",
    "                  'metric': 'binary_logloss', 'cat_smooth': 30,'is_unbalance': True,'boost_from_average': False,\n",
    "                  'num_leaves': 168, 'learning_rate': 0.01}\n",
    "    fit_params_lgb = {'num_boost_round': 10000, 'verbose_eval':100,'early_stopping_rounds':100}\n",
    "    \n",
    "    lgb_reg = lgb.train(params=params_lgb, \n",
    "                        train_set=lgb_trn, \n",
    "                        **fit_params_lgb,\n",
    "                        valid_sets=[lgb_trn, lgb_val])\n",
    "    return lgb_reg\n",
    "\n",
    "def classify(pred):\n",
    "    l = []\n",
    "    for n in pred:\n",
    "        if n>0.5:\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T14:38:09.095910Z",
     "start_time": "2019-12-06T14:35:01.081491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.404741\tvalid_1's binary_logloss: 0.458524\n",
      "[200]\ttraining's binary_logloss: 0.281896\tvalid_1's binary_logloss: 0.376494\n",
      "[300]\ttraining's binary_logloss: 0.199975\tvalid_1's binary_logloss: 0.325447\n",
      "[400]\ttraining's binary_logloss: 0.142892\tvalid_1's binary_logloss: 0.29265\n",
      "[500]\ttraining's binary_logloss: 0.103929\tvalid_1's binary_logloss: 0.275359\n",
      "[600]\ttraining's binary_logloss: 0.0776465\tvalid_1's binary_logloss: 0.268248\n",
      "[700]\ttraining's binary_logloss: 0.0590542\tvalid_1's binary_logloss: 0.266634\n",
      "Early stopping, best iteration is:\n",
      "[696]\ttraining's binary_logloss: 0.0596778\tvalid_1's binary_logloss: 0.266544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.409641\tvalid_1's binary_logloss: 0.457073\n",
      "[200]\ttraining's binary_logloss: 0.286135\tvalid_1's binary_logloss: 0.373302\n",
      "[300]\ttraining's binary_logloss: 0.201867\tvalid_1's binary_logloss: 0.323106\n",
      "[400]\ttraining's binary_logloss: 0.144297\tvalid_1's binary_logloss: 0.2907\n",
      "[500]\ttraining's binary_logloss: 0.105683\tvalid_1's binary_logloss: 0.271502\n",
      "[600]\ttraining's binary_logloss: 0.0792386\tvalid_1's binary_logloss: 0.260541\n",
      "[700]\ttraining's binary_logloss: 0.0604777\tvalid_1's binary_logloss: 0.255051\n",
      "[800]\ttraining's binary_logloss: 0.0468352\tvalid_1's binary_logloss: 0.253279\n",
      "[900]\ttraining's binary_logloss: 0.0364621\tvalid_1's binary_logloss: 0.254198\n",
      "Early stopping, best iteration is:\n",
      "[813]\ttraining's binary_logloss: 0.0452675\tvalid_1's binary_logloss: 0.253028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.408594\tvalid_1's binary_logloss: 0.456881\n",
      "[200]\ttraining's binary_logloss: 0.281991\tvalid_1's binary_logloss: 0.369883\n",
      "[300]\ttraining's binary_logloss: 0.197945\tvalid_1's binary_logloss: 0.317971\n",
      "[400]\ttraining's binary_logloss: 0.140516\tvalid_1's binary_logloss: 0.288096\n",
      "[500]\ttraining's binary_logloss: 0.101891\tvalid_1's binary_logloss: 0.271882\n",
      "[600]\ttraining's binary_logloss: 0.0755661\tvalid_1's binary_logloss: 0.26389\n",
      "[700]\ttraining's binary_logloss: 0.0571366\tvalid_1's binary_logloss: 0.261084\n",
      "[800]\ttraining's binary_logloss: 0.0437735\tvalid_1's binary_logloss: 0.261329\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's binary_logloss: 0.0532387\tvalid_1's binary_logloss: 0.260763\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.406154\tvalid_1's binary_logloss: 0.460014\n",
      "[200]\ttraining's binary_logloss: 0.282581\tvalid_1's binary_logloss: 0.379053\n",
      "[300]\ttraining's binary_logloss: 0.198237\tvalid_1's binary_logloss: 0.326308\n",
      "[400]\ttraining's binary_logloss: 0.140951\tvalid_1's binary_logloss: 0.294351\n",
      "[500]\ttraining's binary_logloss: 0.102438\tvalid_1's binary_logloss: 0.276925\n",
      "[600]\ttraining's binary_logloss: 0.0760896\tvalid_1's binary_logloss: 0.268757\n",
      "[700]\ttraining's binary_logloss: 0.0574509\tvalid_1's binary_logloss: 0.267499\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's binary_logloss: 0.0589025\tvalid_1's binary_logloss: 0.267338\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.408906\tvalid_1's binary_logloss: 0.454598\n",
      "[200]\ttraining's binary_logloss: 0.286304\tvalid_1's binary_logloss: 0.37268\n",
      "[300]\ttraining's binary_logloss: 0.203601\tvalid_1's binary_logloss: 0.315869\n",
      "[400]\ttraining's binary_logloss: 0.145801\tvalid_1's binary_logloss: 0.280856\n",
      "[500]\ttraining's binary_logloss: 0.106021\tvalid_1's binary_logloss: 0.260827\n",
      "[600]\ttraining's binary_logloss: 0.0790205\tvalid_1's binary_logloss: 0.251017\n",
      "[700]\ttraining's binary_logloss: 0.0601441\tvalid_1's binary_logloss: 0.247332\n",
      "[800]\ttraining's binary_logloss: 0.0464683\tvalid_1's binary_logloss: 0.247602\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's binary_logloss: 0.0536357\tvalid_1's binary_logloss: 0.247073\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.406071\tvalid_1's binary_logloss: 0.45498\n",
      "[200]\ttraining's binary_logloss: 0.280482\tvalid_1's binary_logloss: 0.378503\n",
      "[300]\ttraining's binary_logloss: 0.19818\tvalid_1's binary_logloss: 0.331876\n",
      "[400]\ttraining's binary_logloss: 0.141444\tvalid_1's binary_logloss: 0.301743\n",
      "[500]\ttraining's binary_logloss: 0.102754\tvalid_1's binary_logloss: 0.284602\n",
      "[600]\ttraining's binary_logloss: 0.0764178\tvalid_1's binary_logloss: 0.27587\n",
      "[700]\ttraining's binary_logloss: 0.0579227\tvalid_1's binary_logloss: 0.273665\n",
      "Early stopping, best iteration is:\n",
      "[696]\ttraining's binary_logloss: 0.0585306\tvalid_1's binary_logloss: 0.27362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.406023\tvalid_1's binary_logloss: 0.450824\n",
      "[200]\ttraining's binary_logloss: 0.282722\tvalid_1's binary_logloss: 0.3663\n",
      "[300]\ttraining's binary_logloss: 0.200169\tvalid_1's binary_logloss: 0.313712\n",
      "[400]\ttraining's binary_logloss: 0.144877\tvalid_1's binary_logloss: 0.283892\n",
      "[500]\ttraining's binary_logloss: 0.106463\tvalid_1's binary_logloss: 0.264483\n",
      "[600]\ttraining's binary_logloss: 0.0801804\tvalid_1's binary_logloss: 0.253405\n",
      "[700]\ttraining's binary_logloss: 0.0614273\tvalid_1's binary_logloss: 0.247563\n",
      "[800]\ttraining's binary_logloss: 0.0474888\tvalid_1's binary_logloss: 0.245697\n",
      "[900]\ttraining's binary_logloss: 0.0369062\tvalid_1's binary_logloss: 0.246307\n",
      "Early stopping, best iteration is:\n",
      "[819]\ttraining's binary_logloss: 0.0452195\tvalid_1's binary_logloss: 0.245494\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.404878\tvalid_1's binary_logloss: 0.450936\n",
      "[200]\ttraining's binary_logloss: 0.281258\tvalid_1's binary_logloss: 0.374522\n",
      "[300]\ttraining's binary_logloss: 0.19838\tvalid_1's binary_logloss: 0.325272\n",
      "[400]\ttraining's binary_logloss: 0.142901\tvalid_1's binary_logloss: 0.298077\n",
      "[500]\ttraining's binary_logloss: 0.103835\tvalid_1's binary_logloss: 0.283037\n",
      "[600]\ttraining's binary_logloss: 0.0772771\tvalid_1's binary_logloss: 0.276587\n",
      "[700]\ttraining's binary_logloss: 0.0588065\tvalid_1's binary_logloss: 0.27544\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttraining's binary_logloss: 0.0596006\tvalid_1's binary_logloss: 0.27532\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.402238\tvalid_1's binary_logloss: 0.460755\n",
      "[200]\ttraining's binary_logloss: 0.280168\tvalid_1's binary_logloss: 0.378598\n",
      "[300]\ttraining's binary_logloss: 0.198527\tvalid_1's binary_logloss: 0.327091\n",
      "[400]\ttraining's binary_logloss: 0.142768\tvalid_1's binary_logloss: 0.295354\n",
      "[500]\ttraining's binary_logloss: 0.104273\tvalid_1's binary_logloss: 0.275439\n",
      "[600]\ttraining's binary_logloss: 0.0778748\tvalid_1's binary_logloss: 0.264865\n",
      "[700]\ttraining's binary_logloss: 0.0593184\tvalid_1's binary_logloss: 0.259926\n",
      "[800]\ttraining's binary_logloss: 0.0457588\tvalid_1's binary_logloss: 0.258478\n",
      "[900]\ttraining's binary_logloss: 0.0355472\tvalid_1's binary_logloss: 0.259714\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttraining's binary_logloss: 0.0432125\tvalid_1's binary_logloss: 0.258142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.407428\tvalid_1's binary_logloss: 0.449007\n",
      "[200]\ttraining's binary_logloss: 0.282435\tvalid_1's binary_logloss: 0.361267\n",
      "[300]\ttraining's binary_logloss: 0.199987\tvalid_1's binary_logloss: 0.310783\n",
      "[400]\ttraining's binary_logloss: 0.144157\tvalid_1's binary_logloss: 0.277906\n",
      "[500]\ttraining's binary_logloss: 0.105475\tvalid_1's binary_logloss: 0.257731\n",
      "[600]\ttraining's binary_logloss: 0.0792452\tvalid_1's binary_logloss: 0.248147\n",
      "[700]\ttraining's binary_logloss: 0.0605726\tvalid_1's binary_logloss: 0.243744\n",
      "[800]\ttraining's binary_logloss: 0.0467784\tvalid_1's binary_logloss: 0.242593\n",
      "[900]\ttraining's binary_logloss: 0.0364291\tvalid_1's binary_logloss: 0.243918\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's binary_logloss: 0.0467784\tvalid_1's binary_logloss: 0.242593\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83      9012\n",
      "          1       0.93      0.93      0.93     20988\n",
      "\n",
      "avg / total       0.90      0.90      0.90     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "n_splits=10\n",
    "y_pred = []\n",
    "y_true = []\n",
    "sfold = ShuffleSplit(n_splits=n_splits, test_size=0.3)\n",
    "for train_idx, val_idx in sfold.split(x):\n",
    "    train_x = x.iloc[train_idx,:]\n",
    "    train_y = y['label'].iloc[train_idx]\n",
    "    #print(train_x,train_y)\n",
    "    test_x = x.iloc[val_idx,:]\n",
    "    test_y = y['label'].iloc[val_idx]\n",
    "    model = Lgb_Classifier(train_x, train_y, test_x, test_y)\n",
    "    y_pred.extend(classify(model.predict(test_x)))\n",
    "    y_true.extend(test_y)\n",
    "    \n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T17:00:21.847001Z",
     "start_time": "2019-12-06T17:00:21.841402Z"
    }
   },
   "outputs": [],
   "source": [
    "# larger model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_larger(len_col):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(len_col, input_dim=len_col, init='normal', activation='relu'))\n",
    "    from keras.layers import Dropout\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(len_col, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T17:07:31.380972Z",
     "start_time": "2019-12-06T17:04:46.559027Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.8270 - acc: 0.6591\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5308 - acc: 0.7924\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4646 - acc: 0.8246\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4097 - acc: 0.8573\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3717 - acc: 0.8733\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3661 - acc: 0.8881\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3548 - acc: 0.8931\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.3172 - acc: 0.8989\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.3003 - acc: 0.9047\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2758 - acc: 0.9147\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2630 - acc: 0.9157\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2487 - acc: 0.9234\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2296 - acc: 0.9317\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2152 - acc: 0.9386\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.2217 - acc: 0.9389\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.2134 - acc: 0.9409\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1926 - acc: 0.9469\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1659 - acc: 0.9594\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1563 - acc: 0.9667\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1431 - acc: 0.9727\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.8657 - acc: 0.6497\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5574 - acc: 0.7973\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4890 - acc: 0.8263\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4163 - acc: 0.8494\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3620 - acc: 0.8697\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3361 - acc: 0.8821\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3159 - acc: 0.8924\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2927 - acc: 0.9001\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2732 - acc: 0.9084\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2546 - acc: 0.9164\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2454 - acc: 0.9193\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2200 - acc: 0.9299\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2021 - acc: 0.9377\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1823 - acc: 0.9461\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1757 - acc: 0.9516\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1585 - acc: 0.9586\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1408 - acc: 0.9661\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1353 - acc: 0.9716\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1220 - acc: 0.9729\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1146 - acc: 0.9766\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.8117 - acc: 0.6804\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5386 - acc: 0.7907\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4628 - acc: 0.8306\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4094 - acc: 0.8561\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4053 - acc: 0.8731\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3691 - acc: 0.8824\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3325 - acc: 0.8921\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.3071 - acc: 0.8990\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2782 - acc: 0.9141\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2734 - acc: 0.9164\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2458 - acc: 0.9250\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2332 - acc: 0.9297\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2126 - acc: 0.9371\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1925 - acc: 0.9444\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.2009 - acc: 0.9463\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.2099 - acc: 0.9509\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1587 - acc: 0.9616\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1535 - acc: 0.9644\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1556 - acc: 0.9697\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1815 - acc: 0.9666\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.8261 - acc: 0.6556\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5395 - acc: 0.8027\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4695 - acc: 0.8320\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4100 - acc: 0.8581\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3728 - acc: 0.8759\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3685 - acc: 0.8766\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3356 - acc: 0.8874\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2984 - acc: 0.8987\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2937 - acc: 0.9023\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2867 - acc: 0.9130\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2568 - acc: 0.9191\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2461 - acc: 0.9253\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2522 - acc: 0.9256\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2627 - acc: 0.9256\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.2284 - acc: 0.9390\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.2721 - acc: 0.9374\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.2456 - acc: 0.9400\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.2031 - acc: 0.9463\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1789 - acc: 0.9569\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1596 - acc: 0.9639\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.6964 - acc: 0.7300\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4964 - acc: 0.8094\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4374 - acc: 0.8371\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3756 - acc: 0.8660\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3455 - acc: 0.8807\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3203 - acc: 0.8911\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3024 - acc: 0.8959\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2865 - acc: 0.9013\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2656 - acc: 0.9119\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2607 - acc: 0.9220\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2418 - acc: 0.9229\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2157 - acc: 0.9307\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2008 - acc: 0.9390\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1762 - acc: 0.9496\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1731 - acc: 0.9534\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1473 - acc: 0.9619\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1426 - acc: 0.9686\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1658 - acc: 0.9656\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1770 - acc: 0.9670\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1468 - acc: 0.9699\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.7478 - acc: 0.7129\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5245 - acc: 0.8033\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4432 - acc: 0.8327\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3939 - acc: 0.8569\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3489 - acc: 0.8751\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3189 - acc: 0.8909\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2973 - acc: 0.8984\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2776 - acc: 0.9064\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2772 - acc: 0.9113\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2695 - acc: 0.9173\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2491 - acc: 0.9236\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2235 - acc: 0.9330\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2097 - acc: 0.9421\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2258 - acc: 0.9430\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.2046 - acc: 0.9489\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1796 - acc: 0.9564\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1510 - acc: 0.9636\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1367 - acc: 0.9707\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1214 - acc: 0.9754\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1362 - acc: 0.9719\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.9282 - acc: 0.6340\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5342 - acc: 0.7737\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4568 - acc: 0.8260\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4151 - acc: 0.8479\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3706 - acc: 0.8717\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3543 - acc: 0.8754\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3237 - acc: 0.8880\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.3023 - acc: 0.9007\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2814 - acc: 0.9086\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3164 - acc: 0.9073\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2970 - acc: 0.9133\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2350 - acc: 0.9254\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2239 - acc: 0.9319\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2078 - acc: 0.9393\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1971 - acc: 0.9443\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.2549 - acc: 0.9424\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.2041 - acc: 0.9547\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1794 - acc: 0.9566\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1701 - acc: 0.9631\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1847 - acc: 0.9680\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.7485 - acc: 0.7013\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5086 - acc: 0.7991\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4407 - acc: 0.8303\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3917 - acc: 0.8591\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3502 - acc: 0.8749\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3258 - acc: 0.8876\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2980 - acc: 0.8987\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2763 - acc: 0.9033\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2603 - acc: 0.9150\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2483 - acc: 0.9211\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2302 - acc: 0.9274\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2035 - acc: 0.9373\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1995 - acc: 0.9430\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1736 - acc: 0.9520\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1622 - acc: 0.9583\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1398 - acc: 0.9674\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1257 - acc: 0.9739\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1134 - acc: 0.9749\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1239 - acc: 0.9769\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1189 - acc: 0.9786\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.84      0.83      7244\n",
      "          1       0.93      0.92      0.92     16756\n",
      "\n",
      "avg / total       0.90      0.89      0.89     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits=10\n",
    "predictions = x.columns\n",
    "sfold = ShuffleSplit(n_splits=n_splits, test_size=0.3)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for train_idx, val_idx in sfold.split(x):\n",
    "    train_x = x[predictions].iloc[train_idx]\n",
    "    train_y = y['label'].iloc[train_idx]\n",
    "    #print(train_x,train_y)\n",
    "    test_x = x[predictions].iloc[val_idx]\n",
    "    test_y = y['label'].iloc[val_idx]\n",
    "    len_col = train_x.shape[1]\n",
    "    nn_model = create_larger(len_col)\n",
    "    nn_model.fit(train_x, train_y, nb_epoch=20, batch_size=512,  verbose=2)\n",
    "\n",
    "    y_pred.extend(classify(nn_model.predict(test_x).T[0].tolist()))\n",
    "    y_true.extend(test_y)\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#多模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T14:58:36.006199Z",
     "start_time": "2019-12-06T14:43:13.594900Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.403839\tvalid_1's binary_logloss: 0.463303\n",
      "[200]\ttraining's binary_logloss: 0.278333\tvalid_1's binary_logloss: 0.381955\n",
      "[300]\ttraining's binary_logloss: 0.197095\tvalid_1's binary_logloss: 0.332232\n",
      "[400]\ttraining's binary_logloss: 0.140718\tvalid_1's binary_logloss: 0.300341\n",
      "[500]\ttraining's binary_logloss: 0.102576\tvalid_1's binary_logloss: 0.281665\n",
      "[600]\ttraining's binary_logloss: 0.0765909\tvalid_1's binary_logloss: 0.272084\n",
      "[700]\ttraining's binary_logloss: 0.0584244\tvalid_1's binary_logloss: 0.269387\n",
      "[800]\ttraining's binary_logloss: 0.0448643\tvalid_1's binary_logloss: 0.269867\n",
      "Early stopping, best iteration is:\n",
      "[735]\ttraining's binary_logloss: 0.0532381\tvalid_1's binary_logloss: 0.269102\n",
      "[0]\tvalidation_0-error:0.211333\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.148\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6356285\ttest: 0.6350615\tbest: 0.6350615 (0)\ttotal: 14.1ms\tremaining: 14.1s\n",
      "100:\tlearn: 0.2861147\ttest: 0.3246656\tbest: 0.3246656 (100)\ttotal: 1.05s\tremaining: 9.33s\n",
      "200:\tlearn: 0.2335153\ttest: 0.3003192\tbest: 0.3002593 (199)\ttotal: 2.17s\tremaining: 8.63s\n",
      "300:\tlearn: 0.1994298\ttest: 0.2870625\tbest: 0.2870320 (299)\ttotal: 3.33s\tremaining: 7.75s\n",
      "400:\tlearn: 0.1756990\ttest: 0.2762636\tbest: 0.2762607 (399)\ttotal: 4.34s\tremaining: 6.48s\n",
      "500:\tlearn: 0.1580523\ttest: 0.2697862\tbest: 0.2697862 (500)\ttotal: 5.34s\tremaining: 5.32s\n",
      "600:\tlearn: 0.1429504\ttest: 0.2641627\tbest: 0.2641627 (600)\ttotal: 6.47s\tremaining: 4.3s\n",
      "700:\tlearn: 0.1315177\ttest: 0.2612930\tbest: 0.2612799 (698)\ttotal: 7.59s\tremaining: 3.24s\n",
      "800:\tlearn: 0.1215934\ttest: 0.2599772\tbest: 0.2599772 (800)\ttotal: 8.78s\tremaining: 2.18s\n",
      "900:\tlearn: 0.1129838\ttest: 0.2577601\tbest: 0.2575745 (893)\ttotal: 9.99s\tremaining: 1.1s\n",
      "999:\tlearn: 0.1048922\ttest: 0.2558636\tbest: 0.2558636 (999)\ttotal: 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2558635801\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.7781 - acc: 0.6824\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5084 - acc: 0.7991\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4430 - acc: 0.8401\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4038 - acc: 0.8613\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3623 - acc: 0.8801\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3332 - acc: 0.8877\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3047 - acc: 0.9021\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2988 - acc: 0.9073\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2664 - acc: 0.9177\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2460 - acc: 0.9269\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2500 - acc: 0.9301\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2504 - acc: 0.9360\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2185 - acc: 0.9410\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2035 - acc: 0.9463\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1787 - acc: 0.9560\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1618 - acc: 0.9630\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1453 - acc: 0.9690\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1367 - acc: 0.9741\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1314 - acc: 0.9753\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1458 - acc: 0.9744\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.40233\tvalid_1's binary_logloss: 0.467821\n",
      "[200]\ttraining's binary_logloss: 0.280678\tvalid_1's binary_logloss: 0.393822\n",
      "[300]\ttraining's binary_logloss: 0.197405\tvalid_1's binary_logloss: 0.342563\n",
      "[400]\ttraining's binary_logloss: 0.141789\tvalid_1's binary_logloss: 0.314154\n",
      "[500]\ttraining's binary_logloss: 0.103057\tvalid_1's binary_logloss: 0.297686\n",
      "[600]\ttraining's binary_logloss: 0.0767405\tvalid_1's binary_logloss: 0.291719\n",
      "[700]\ttraining's binary_logloss: 0.0580542\tvalid_1's binary_logloss: 0.290579\n",
      "Early stopping, best iteration is:\n",
      "[687]\ttraining's binary_logloss: 0.0601251\tvalid_1's binary_logloss: 0.290397\n",
      "[0]\tvalidation_0-error:0.226\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.152667\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6329073\ttest: 0.6369779\tbest: 0.6369779 (0)\ttotal: 18.1ms\tremaining: 18.1s\n",
      "100:\tlearn: 0.2821972\ttest: 0.3321983\tbest: 0.3321983 (100)\ttotal: 1.19s\tremaining: 10.6s\n",
      "200:\tlearn: 0.2269129\ttest: 0.3025394\tbest: 0.3025394 (200)\ttotal: 2.21s\tremaining: 8.79s\n",
      "300:\tlearn: 0.1961451\ttest: 0.2877347\tbest: 0.2877347 (300)\ttotal: 3.34s\tremaining: 7.75s\n",
      "400:\tlearn: 0.1738189\ttest: 0.2788068\tbest: 0.2786978 (396)\ttotal: 4.35s\tremaining: 6.5s\n",
      "500:\tlearn: 0.1551367\ttest: 0.2725736\tbest: 0.2725736 (500)\ttotal: 5.34s\tremaining: 5.32s\n",
      "600:\tlearn: 0.1410567\ttest: 0.2687330\tbest: 0.2687330 (600)\ttotal: 6.36s\tremaining: 4.22s\n",
      "700:\tlearn: 0.1293594\ttest: 0.2655697\tbest: 0.2655266 (699)\ttotal: 7.37s\tremaining: 3.14s\n",
      "800:\tlearn: 0.1182959\ttest: 0.2648946\tbest: 0.2646063 (750)\ttotal: 8.47s\tremaining: 2.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2646063022\n",
      "bestIteration = 750\n",
      "\n",
      "Shrink model to first 751 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.7022 - acc: 0.7153\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4779 - acc: 0.8030\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4184 - acc: 0.8403\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3579 - acc: 0.8704\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3177 - acc: 0.8860\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2904 - acc: 0.8966\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3350 - acc: 0.8983\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2630 - acc: 0.9121\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2395 - acc: 0.9211\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2253 - acc: 0.9254\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.1981 - acc: 0.9387\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.1910 - acc: 0.9427\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1584 - acc: 0.9543\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1497 - acc: 0.9600\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1290 - acc: 0.9673\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1147 - acc: 0.9736\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1050 - acc: 0.9741\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1428 - acc: 0.9727\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1179 - acc: 0.9770\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1120 - acc: 0.9760\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.402389\tvalid_1's binary_logloss: 0.463034\n",
      "[200]\ttraining's binary_logloss: 0.278697\tvalid_1's binary_logloss: 0.386425\n",
      "[300]\ttraining's binary_logloss: 0.196242\tvalid_1's binary_logloss: 0.340049\n",
      "[400]\ttraining's binary_logloss: 0.138821\tvalid_1's binary_logloss: 0.311528\n",
      "[500]\ttraining's binary_logloss: 0.100506\tvalid_1's binary_logloss: 0.294861\n",
      "[600]\ttraining's binary_logloss: 0.0744609\tvalid_1's binary_logloss: 0.28626\n",
      "[700]\ttraining's binary_logloss: 0.0562112\tvalid_1's binary_logloss: 0.284487\n",
      "Early stopping, best iteration is:\n",
      "[670]\ttraining's binary_logloss: 0.0611117\tvalid_1's binary_logloss: 0.284263\n",
      "[0]\tvalidation_0-error:0.219\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.162\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6345343\ttest: 0.6386869\tbest: 0.6386869 (0)\ttotal: 12.6ms\tremaining: 12.5s\n",
      "100:\tlearn: 0.2816363\ttest: 0.3382523\tbest: 0.3382523 (100)\ttotal: 1.08s\tremaining: 9.61s\n",
      "200:\tlearn: 0.2278178\ttest: 0.3091091\tbest: 0.3091091 (200)\ttotal: 2.17s\tremaining: 8.61s\n",
      "300:\tlearn: 0.1966972\ttest: 0.2955389\tbest: 0.2955389 (300)\ttotal: 3.32s\tremaining: 7.71s\n",
      "400:\tlearn: 0.1731760\ttest: 0.2867014\tbest: 0.2867014 (400)\ttotal: 4.33s\tremaining: 6.46s\n",
      "500:\tlearn: 0.1544231\ttest: 0.2811526\tbest: 0.2811526 (500)\ttotal: 5.43s\tremaining: 5.41s\n",
      "600:\tlearn: 0.1396294\ttest: 0.2776136\tbest: 0.2775904 (599)\ttotal: 6.48s\tremaining: 4.3s\n",
      "700:\tlearn: 0.1268699\ttest: 0.2752374\tbest: 0.2752140 (696)\ttotal: 7.49s\tremaining: 3.19s\n",
      "800:\tlearn: 0.1172042\ttest: 0.2720431\tbest: 0.2718657 (793)\ttotal: 8.54s\tremaining: 2.12s\n",
      "900:\tlearn: 0.1086280\ttest: 0.2703430\tbest: 0.2698513 (883)\ttotal: 9.57s\tremaining: 1.05s\n",
      "999:\tlearn: 0.1009598\ttest: 0.2697911\tbest: 0.2695529 (988)\ttotal: 10.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.269552932\n",
      "bestIteration = 988\n",
      "\n",
      "Shrink model to first 989 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.7524 - acc: 0.6857\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4946 - acc: 0.8060\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4307 - acc: 0.8414\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3794 - acc: 0.8681\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3439 - acc: 0.8787\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3166 - acc: 0.8934\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3007 - acc: 0.8973\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2824 - acc: 0.9070\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2825 - acc: 0.9047\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2562 - acc: 0.9124\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2399 - acc: 0.9224\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2321 - acc: 0.9231\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2075 - acc: 0.9353\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2066 - acc: 0.9407\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1734 - acc: 0.9543\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1566 - acc: 0.9580\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1466 - acc: 0.9637\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1659 - acc: 0.9573\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1458 - acc: 0.9667\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1210 - acc: 0.9747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.40114\tvalid_1's binary_logloss: 0.462194\n",
      "[200]\ttraining's binary_logloss: 0.278191\tvalid_1's binary_logloss: 0.386573\n",
      "[300]\ttraining's binary_logloss: 0.195967\tvalid_1's binary_logloss: 0.338094\n",
      "[400]\ttraining's binary_logloss: 0.138913\tvalid_1's binary_logloss: 0.306718\n",
      "[500]\ttraining's binary_logloss: 0.101\tvalid_1's binary_logloss: 0.289216\n",
      "[600]\ttraining's binary_logloss: 0.0753317\tvalid_1's binary_logloss: 0.280985\n",
      "[700]\ttraining's binary_logloss: 0.0571694\tvalid_1's binary_logloss: 0.277596\n",
      "[800]\ttraining's binary_logloss: 0.0438705\tvalid_1's binary_logloss: 0.278445\n",
      "Early stopping, best iteration is:\n",
      "[712]\ttraining's binary_logloss: 0.0553306\tvalid_1's binary_logloss: 0.277302\n",
      "[0]\tvalidation_0-error:0.234333\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.157\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6356594\ttest: 0.6371583\tbest: 0.6371583 (0)\ttotal: 12.2ms\tremaining: 12.2s\n",
      "100:\tlearn: 0.2831146\ttest: 0.3332308\tbest: 0.3332308 (100)\ttotal: 1.16s\tremaining: 10.3s\n",
      "200:\tlearn: 0.2290676\ttest: 0.3037209\tbest: 0.3037209 (200)\ttotal: 2.29s\tremaining: 9.11s\n",
      "300:\tlearn: 0.1986758\ttest: 0.2891249\tbest: 0.2891097 (299)\ttotal: 3.51s\tremaining: 8.15s\n",
      "400:\tlearn: 0.1771671\ttest: 0.2792473\tbest: 0.2792473 (400)\ttotal: 4.56s\tremaining: 6.82s\n",
      "500:\tlearn: 0.1581673\ttest: 0.2715417\tbest: 0.2715417 (500)\ttotal: 5.61s\tremaining: 5.58s\n",
      "600:\tlearn: 0.1447048\ttest: 0.2663785\tbest: 0.2663785 (600)\ttotal: 6.65s\tremaining: 4.41s\n",
      "700:\tlearn: 0.1320406\ttest: 0.2625412\tbest: 0.2624407 (696)\ttotal: 7.69s\tremaining: 3.28s\n",
      "800:\tlearn: 0.1214054\ttest: 0.2590397\tbest: 0.2589712 (799)\ttotal: 8.79s\tremaining: 2.18s\n",
      "900:\tlearn: 0.1122363\ttest: 0.2574867\tbest: 0.2572308 (893)\ttotal: 9.84s\tremaining: 1.08s\n",
      "999:\tlearn: 0.1044403\ttest: 0.2552355\tbest: 0.2552216 (997)\ttotal: 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2552215591\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.6652 - acc: 0.7317\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4765 - acc: 0.8171\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4101 - acc: 0.8476\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3644 - acc: 0.8683\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3307 - acc: 0.8841\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3016 - acc: 0.8937\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2777 - acc: 0.9077\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2697 - acc: 0.9089\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2529 - acc: 0.9180\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2292 - acc: 0.9269\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2221 - acc: 0.9319\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2009 - acc: 0.9364\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1834 - acc: 0.9456\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1570 - acc: 0.9580\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1678 - acc: 0.9567\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1492 - acc: 0.9656\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1201 - acc: 0.9714\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1441 - acc: 0.9626\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1248 - acc: 0.9740\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1084 - acc: 0.9813\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.403638\tvalid_1's binary_logloss: 0.459268\n",
      "[200]\ttraining's binary_logloss: 0.279829\tvalid_1's binary_logloss: 0.379065\n",
      "[300]\ttraining's binary_logloss: 0.197247\tvalid_1's binary_logloss: 0.328393\n",
      "[400]\ttraining's binary_logloss: 0.140892\tvalid_1's binary_logloss: 0.297073\n",
      "[500]\ttraining's binary_logloss: 0.10306\tvalid_1's binary_logloss: 0.280329\n",
      "[600]\ttraining's binary_logloss: 0.0772589\tvalid_1's binary_logloss: 0.271305\n",
      "[700]\ttraining's binary_logloss: 0.05896\tvalid_1's binary_logloss: 0.267925\n",
      "[800]\ttraining's binary_logloss: 0.0454692\tvalid_1's binary_logloss: 0.268415\n",
      "Early stopping, best iteration is:\n",
      "[738]\ttraining's binary_logloss: 0.0532604\tvalid_1's binary_logloss: 0.267423\n",
      "[0]\tvalidation_0-error:0.213333\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.160667\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6325341\ttest: 0.6345905\tbest: 0.6345905 (0)\ttotal: 11.5ms\tremaining: 11.5s\n",
      "100:\tlearn: 0.2841330\ttest: 0.3344328\tbest: 0.3344328 (100)\ttotal: 1.02s\tremaining: 9.12s\n",
      "200:\tlearn: 0.2304447\ttest: 0.3037648\tbest: 0.3037648 (200)\ttotal: 2.13s\tremaining: 8.47s\n",
      "300:\tlearn: 0.1973290\ttest: 0.2884686\tbest: 0.2884686 (300)\ttotal: 3.3s\tremaining: 7.66s\n",
      "400:\tlearn: 0.1764098\ttest: 0.2791995\tbest: 0.2791713 (398)\ttotal: 4.31s\tremaining: 6.44s\n",
      "500:\tlearn: 0.1605533\ttest: 0.2748335\tbest: 0.2748078 (495)\ttotal: 5.33s\tremaining: 5.31s\n",
      "600:\tlearn: 0.1447892\ttest: 0.2708052\tbest: 0.2708052 (600)\ttotal: 6.34s\tremaining: 4.21s\n",
      "700:\tlearn: 0.1330539\ttest: 0.2669294\tbest: 0.2667999 (689)\ttotal: 7.34s\tremaining: 3.13s\n",
      "800:\tlearn: 0.1223147\ttest: 0.2637843\tbest: 0.2637734 (798)\ttotal: 8.35s\tremaining: 2.08s\n",
      "900:\tlearn: 0.1134053\ttest: 0.2617235\tbest: 0.2616760 (871)\ttotal: 9.38s\tremaining: 1.03s\n",
      "999:\tlearn: 0.1060972\ttest: 0.2599310\tbest: 0.2599310 (999)\ttotal: 10.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2599310078\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.8178 - acc: 0.6740\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5354 - acc: 0.7959\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4729 - acc: 0.8300\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4745 - acc: 0.8476\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3600 - acc: 0.8691\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3280 - acc: 0.8833\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3172 - acc: 0.8870\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2859 - acc: 0.9020\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2697 - acc: 0.9124\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2577 - acc: 0.9141\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2459 - acc: 0.9186\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2210 - acc: 0.9271\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2015 - acc: 0.9379\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2008 - acc: 0.9413\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1709 - acc: 0.9494\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1605 - acc: 0.9546\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1360 - acc: 0.9650\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1428 - acc: 0.9629\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1272 - acc: 0.9701\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1122 - acc: 0.9759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.407371\tvalid_1's binary_logloss: 0.458778\n",
      "[200]\ttraining's binary_logloss: 0.284145\tvalid_1's binary_logloss: 0.378677\n",
      "[300]\ttraining's binary_logloss: 0.201147\tvalid_1's binary_logloss: 0.324746\n",
      "[400]\ttraining's binary_logloss: 0.143413\tvalid_1's binary_logloss: 0.291654\n",
      "[500]\ttraining's binary_logloss: 0.103786\tvalid_1's binary_logloss: 0.269731\n",
      "[600]\ttraining's binary_logloss: 0.0770043\tvalid_1's binary_logloss: 0.259553\n",
      "[700]\ttraining's binary_logloss: 0.0582159\tvalid_1's binary_logloss: 0.255472\n",
      "[800]\ttraining's binary_logloss: 0.044581\tvalid_1's binary_logloss: 0.254704\n",
      "Early stopping, best iteration is:\n",
      "[762]\ttraining's binary_logloss: 0.0492982\tvalid_1's binary_logloss: 0.254401\n",
      "[0]\tvalidation_0-error:0.210667\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.155333\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6363706\ttest: 0.6371802\tbest: 0.6371802 (0)\ttotal: 12.1ms\tremaining: 12.1s\n",
      "100:\tlearn: 0.2913674\ttest: 0.3226132\tbest: 0.3226132 (100)\ttotal: 1.06s\tremaining: 9.44s\n",
      "200:\tlearn: 0.2347735\ttest: 0.2913878\tbest: 0.2913753 (199)\ttotal: 2.32s\tremaining: 9.23s\n",
      "300:\tlearn: 0.2008947\ttest: 0.2735865\tbest: 0.2735865 (300)\ttotal: 3.52s\tremaining: 8.16s\n",
      "400:\tlearn: 0.1776643\ttest: 0.2630193\tbest: 0.2630193 (400)\ttotal: 4.57s\tremaining: 6.82s\n",
      "500:\tlearn: 0.1586735\ttest: 0.2549748\tbest: 0.2549555 (498)\ttotal: 5.66s\tremaining: 5.64s\n",
      "600:\tlearn: 0.1434379\ttest: 0.2491829\tbest: 0.2491829 (600)\ttotal: 6.72s\tremaining: 4.46s\n",
      "700:\tlearn: 0.1309995\ttest: 0.2449767\tbest: 0.2449292 (698)\ttotal: 7.79s\tremaining: 3.32s\n",
      "800:\tlearn: 0.1197073\ttest: 0.2422969\tbest: 0.2422969 (800)\ttotal: 8.85s\tremaining: 2.2s\n",
      "900:\tlearn: 0.1103175\ttest: 0.2400967\tbest: 0.2399490 (894)\ttotal: 9.92s\tremaining: 1.09s\n",
      "999:\tlearn: 0.1022503\ttest: 0.2378873\tbest: 0.2378873 (999)\ttotal: 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.237887263\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.7603 - acc: 0.6941\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5146 - acc: 0.8007\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4415 - acc: 0.8370\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4376 - acc: 0.8580\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4097 - acc: 0.8684\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3667 - acc: 0.8829\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3387 - acc: 0.8926\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.3038 - acc: 0.8996\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2765 - acc: 0.9076\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2806 - acc: 0.9110\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2674 - acc: 0.9103\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2447 - acc: 0.9231\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2580 - acc: 0.9299\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2226 - acc: 0.9366\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.2070 - acc: 0.9396\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.2092 - acc: 0.9461\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1714 - acc: 0.9557\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1598 - acc: 0.9624\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1350 - acc: 0.9696\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1265 - acc: 0.9726\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.403918\tvalid_1's binary_logloss: 0.460582\n",
      "[200]\ttraining's binary_logloss: 0.282153\tvalid_1's binary_logloss: 0.382619\n",
      "[300]\ttraining's binary_logloss: 0.198757\tvalid_1's binary_logloss: 0.331692\n",
      "[400]\ttraining's binary_logloss: 0.142839\tvalid_1's binary_logloss: 0.300297\n",
      "[500]\ttraining's binary_logloss: 0.104469\tvalid_1's binary_logloss: 0.280346\n",
      "[600]\ttraining's binary_logloss: 0.0780369\tvalid_1's binary_logloss: 0.268973\n",
      "[700]\ttraining's binary_logloss: 0.0595185\tvalid_1's binary_logloss: 0.264093\n",
      "[800]\ttraining's binary_logloss: 0.0458622\tvalid_1's binary_logloss: 0.261704\n",
      "[900]\ttraining's binary_logloss: 0.0355859\tvalid_1's binary_logloss: 0.261936\n",
      "Early stopping, best iteration is:\n",
      "[804]\ttraining's binary_logloss: 0.0453982\tvalid_1's binary_logloss: 0.261571\n",
      "[0]\tvalidation_0-error:0.222667\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.151667\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6352164\ttest: 0.6368260\tbest: 0.6368260 (0)\ttotal: 23.7ms\tremaining: 23.7s\n",
      "100:\tlearn: 0.2878468\ttest: 0.3270170\tbest: 0.3270170 (100)\ttotal: 1.42s\tremaining: 12.6s\n",
      "200:\tlearn: 0.2324159\ttest: 0.2969110\tbest: 0.2969110 (200)\ttotal: 6.2s\tremaining: 24.6s\n",
      "300:\tlearn: 0.1996834\ttest: 0.2814801\tbest: 0.2814625 (299)\ttotal: 9.67s\tremaining: 22.5s\n",
      "400:\tlearn: 0.1784919\ttest: 0.2726807\tbest: 0.2726807 (400)\ttotal: 12.8s\tremaining: 19.1s\n",
      "500:\tlearn: 0.1598591\ttest: 0.2646283\tbest: 0.2646283 (500)\ttotal: 16.5s\tremaining: 16.4s\n",
      "600:\tlearn: 0.1457888\ttest: 0.2588333\tbest: 0.2587795 (599)\ttotal: 19.7s\tremaining: 13.1s\n",
      "700:\tlearn: 0.1333325\ttest: 0.2554518\tbest: 0.2553564 (697)\ttotal: 23.7s\tremaining: 10.1s\n",
      "800:\tlearn: 0.1219901\ttest: 0.2523043\tbest: 0.2522143 (797)\ttotal: 27.3s\tremaining: 6.79s\n",
      "900:\tlearn: 0.1130886\ttest: 0.2494912\tbest: 0.2494912 (900)\ttotal: 31s\tremaining: 3.4s\n",
      "999:\tlearn: 0.1056162\ttest: 0.2472473\tbest: 0.2472375 (997)\ttotal: 34.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2472375315\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 7s - loss: 0.8502 - acc: 0.6624\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.5114 - acc: 0.7991\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.4400 - acc: 0.8356\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.3839 - acc: 0.8594\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.3457 - acc: 0.8803\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.3231 - acc: 0.8921\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.3121 - acc: 0.9003\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2901 - acc: 0.9031\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.2700 - acc: 0.9113\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.2464 - acc: 0.9187\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.2365 - acc: 0.9239\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.2160 - acc: 0.9329\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1997 - acc: 0.9406\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.1976 - acc: 0.9419\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.1871 - acc: 0.9466\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.1634 - acc: 0.9573\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.1417 - acc: 0.9674\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.1341 - acc: 0.9697\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.1214 - acc: 0.9740\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.1186 - acc: 0.9771\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.403682\tvalid_1's binary_logloss: 0.46439\n",
      "[200]\ttraining's binary_logloss: 0.27875\tvalid_1's binary_logloss: 0.388443\n",
      "[300]\ttraining's binary_logloss: 0.196802\tvalid_1's binary_logloss: 0.340021\n",
      "[400]\ttraining's binary_logloss: 0.139571\tvalid_1's binary_logloss: 0.308495\n",
      "[500]\ttraining's binary_logloss: 0.101647\tvalid_1's binary_logloss: 0.289037\n",
      "[600]\ttraining's binary_logloss: 0.0756257\tvalid_1's binary_logloss: 0.279253\n",
      "[700]\ttraining's binary_logloss: 0.0572366\tvalid_1's binary_logloss: 0.275719\n",
      "[800]\ttraining's binary_logloss: 0.0439106\tvalid_1's binary_logloss: 0.275969\n",
      "Early stopping, best iteration is:\n",
      "[731]\ttraining's binary_logloss: 0.0526872\tvalid_1's binary_logloss: 0.275528\n",
      "[0]\tvalidation_0-error:0.217\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.154667\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6339283\ttest: 0.6344189\tbest: 0.6344189 (0)\ttotal: 16.4ms\tremaining: 16.3s\n",
      "100:\tlearn: 0.2863799\ttest: 0.3281095\tbest: 0.3281095 (100)\ttotal: 1.1s\tremaining: 9.81s\n",
      "200:\tlearn: 0.2302743\ttest: 0.2991562\tbest: 0.2991562 (200)\ttotal: 2.22s\tremaining: 8.84s\n",
      "300:\tlearn: 0.1982583\ttest: 0.2862882\tbest: 0.2862882 (300)\ttotal: 3.48s\tremaining: 8.09s\n",
      "400:\tlearn: 0.1767569\ttest: 0.2775409\tbest: 0.2775409 (400)\ttotal: 4.54s\tremaining: 6.79s\n",
      "500:\tlearn: 0.1594158\ttest: 0.2718194\tbest: 0.2717578 (489)\ttotal: 5.61s\tremaining: 5.59s\n",
      "600:\tlearn: 0.1441726\ttest: 0.2676711\tbest: 0.2676529 (599)\ttotal: 6.67s\tremaining: 4.43s\n",
      "700:\tlearn: 0.1321027\ttest: 0.2665757\tbest: 0.2660976 (679)\ttotal: 7.74s\tremaining: 3.3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2660976428\n",
      "bestIteration = 679\n",
      "\n",
      "Shrink model to first 680 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.7292 - acc: 0.7014\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5314 - acc: 0.8034\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4811 - acc: 0.8367\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4087 - acc: 0.8464\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3692 - acc: 0.8727\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3274 - acc: 0.8887\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3313 - acc: 0.8956\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2891 - acc: 0.9053\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2875 - acc: 0.9064\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2649 - acc: 0.9161\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2395 - acc: 0.9254\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2424 - acc: 0.9336\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.2357 - acc: 0.9374\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2662 - acc: 0.9436\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.2286 - acc: 0.9444\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1856 - acc: 0.9511\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1604 - acc: 0.9614\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1492 - acc: 0.9680\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1330 - acc: 0.9736\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1233 - acc: 0.9759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.406523\tvalid_1's binary_logloss: 0.455357\n",
      "[200]\ttraining's binary_logloss: 0.281679\tvalid_1's binary_logloss: 0.370827\n",
      "[300]\ttraining's binary_logloss: 0.197701\tvalid_1's binary_logloss: 0.317359\n",
      "[400]\ttraining's binary_logloss: 0.140838\tvalid_1's binary_logloss: 0.285745\n",
      "[500]\ttraining's binary_logloss: 0.102529\tvalid_1's binary_logloss: 0.267991\n",
      "[600]\ttraining's binary_logloss: 0.0767351\tvalid_1's binary_logloss: 0.259483\n",
      "[700]\ttraining's binary_logloss: 0.0584094\tvalid_1's binary_logloss: 0.255861\n",
      "[800]\ttraining's binary_logloss: 0.0449577\tvalid_1's binary_logloss: 0.255235\n",
      "Early stopping, best iteration is:\n",
      "[767]\ttraining's binary_logloss: 0.0489737\tvalid_1's binary_logloss: 0.255095\n",
      "[0]\tvalidation_0-error:0.204\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.145\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6373773\ttest: 0.6364975\tbest: 0.6364975 (0)\ttotal: 18.8ms\tremaining: 18.8s\n",
      "100:\tlearn: 0.2929974\ttest: 0.3139223\tbest: 0.3139223 (100)\ttotal: 1.26s\tremaining: 11.2s\n",
      "200:\tlearn: 0.2366851\ttest: 0.2857906\tbest: 0.2857906 (200)\ttotal: 2.4s\tremaining: 9.53s\n",
      "300:\tlearn: 0.2034367\ttest: 0.2726664\tbest: 0.2726664 (300)\ttotal: 3.76s\tremaining: 8.73s\n",
      "400:\tlearn: 0.1803739\ttest: 0.2652044\tbest: 0.2652044 (400)\ttotal: 4.9s\tremaining: 7.32s\n",
      "500:\tlearn: 0.1635020\ttest: 0.2591726\tbest: 0.2591726 (500)\ttotal: 6.02s\tremaining: 6s\n",
      "600:\tlearn: 0.1483722\ttest: 0.2551211\tbest: 0.2551211 (600)\ttotal: 7.15s\tremaining: 4.75s\n",
      "700:\tlearn: 0.1360923\ttest: 0.2522345\tbest: 0.2522204 (699)\ttotal: 8.28s\tremaining: 3.53s\n",
      "800:\tlearn: 0.1252036\ttest: 0.2492403\tbest: 0.2491068 (795)\ttotal: 9.42s\tremaining: 2.34s\n",
      "900:\tlearn: 0.1163182\ttest: 0.2479075\tbest: 0.2478034 (899)\ttotal: 10.6s\tremaining: 1.16s\n",
      "999:\tlearn: 0.1089686\ttest: 0.2465442\tbest: 0.2465442 (999)\ttotal: 11.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2465441625\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.8659 - acc: 0.6744\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4969 - acc: 0.8030\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4341 - acc: 0.8406\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3834 - acc: 0.8610\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3472 - acc: 0.8767\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3317 - acc: 0.8897\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2959 - acc: 0.9011\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2728 - acc: 0.9053\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2654 - acc: 0.9136\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2455 - acc: 0.9173\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2845 - acc: 0.9210\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2157 - acc: 0.9337\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1987 - acc: 0.9387\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1763 - acc: 0.9533\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1615 - acc: 0.9567\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1498 - acc: 0.9644\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1410 - acc: 0.9687\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1254 - acc: 0.9724\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1103 - acc: 0.9770\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1141 - acc: 0.9791\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.406466\tvalid_1's binary_logloss: 0.452583\n",
      "[200]\ttraining's binary_logloss: 0.282129\tvalid_1's binary_logloss: 0.372722\n",
      "[300]\ttraining's binary_logloss: 0.197679\tvalid_1's binary_logloss: 0.318741\n",
      "[400]\ttraining's binary_logloss: 0.14166\tvalid_1's binary_logloss: 0.285332\n",
      "[500]\ttraining's binary_logloss: 0.103139\tvalid_1's binary_logloss: 0.266069\n",
      "[600]\ttraining's binary_logloss: 0.0768475\tvalid_1's binary_logloss: 0.256021\n",
      "[700]\ttraining's binary_logloss: 0.0582711\tvalid_1's binary_logloss: 0.251179\n",
      "[800]\ttraining's binary_logloss: 0.0445872\tvalid_1's binary_logloss: 0.250914\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's binary_logloss: 0.0542874\tvalid_1's binary_logloss: 0.250581\n",
      "[0]\tvalidation_0-error:0.213333\n",
      "Will train until validation_0-error hasn't improved in 50 rounds.\n",
      "[99]\tvalidation_0-error:0.148667\n",
      "Learning rate set to 0.095716\n",
      "0:\tlearn: 0.6368002\ttest: 0.6380284\tbest: 0.6380284 (0)\ttotal: 18.7ms\tremaining: 18.7s\n",
      "100:\tlearn: 0.2905316\ttest: 0.3231296\tbest: 0.3231296 (100)\ttotal: 1.75s\tremaining: 15.6s\n",
      "200:\tlearn: 0.2364027\ttest: 0.2941262\tbest: 0.2941262 (200)\ttotal: 3.48s\tremaining: 13.8s\n",
      "300:\tlearn: 0.2018074\ttest: 0.2768010\tbest: 0.2768010 (300)\ttotal: 5.12s\tremaining: 11.9s\n",
      "400:\tlearn: 0.1771714\ttest: 0.2655484\tbest: 0.2655484 (400)\ttotal: 6.78s\tremaining: 10.1s\n",
      "500:\tlearn: 0.1579422\ttest: 0.2571593\tbest: 0.2571593 (500)\ttotal: 8.42s\tremaining: 8.38s\n",
      "600:\tlearn: 0.1436092\ttest: 0.2512635\tbest: 0.2512432 (599)\ttotal: 9.9s\tremaining: 6.57s\n",
      "700:\tlearn: 0.1312743\ttest: 0.2468208\tbest: 0.2468208 (700)\ttotal: 11.4s\tremaining: 4.87s\n",
      "800:\tlearn: 0.1212515\ttest: 0.2434861\tbest: 0.2434861 (800)\ttotal: 13s\tremaining: 3.23s\n",
      "900:\tlearn: 0.1124187\ttest: 0.2407147\tbest: 0.2407030 (897)\ttotal: 14.5s\tremaining: 1.6s\n",
      "999:\tlearn: 0.1043107\ttest: 0.2390591\tbest: 0.2390190 (998)\ttotal: 16.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2390189804\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1004, input_dim=1004, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 3s - loss: 0.7329 - acc: 0.6973\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4867 - acc: 0.8010\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4284 - acc: 0.8400\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3816 - acc: 0.8569\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3368 - acc: 0.8787\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3200 - acc: 0.8844\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2910 - acc: 0.8963\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2773 - acc: 0.9033\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2555 - acc: 0.9139\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2766 - acc: 0.9206\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2689 - acc: 0.9277\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.2272 - acc: 0.9327\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1932 - acc: 0.9399\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.2014 - acc: 0.9504\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1699 - acc: 0.9529\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1523 - acc: 0.9596\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1295 - acc: 0.9677\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1225 - acc: 0.9756\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1503 - acc: 0.9716\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1180 - acc: 0.9734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84      9095\n",
      "          1       0.92      0.95      0.93     20905\n",
      "\n",
      "avg / total       0.90      0.90      0.90     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits=10\n",
    "predictions = x_train.columns\n",
    "sfold = ShuffleSplit(n_splits=n_splits, test_size=0.3)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for train_idx, val_idx in sfold.split(x_train):\n",
    "    train_x = x[predictions].iloc[train_idx]\n",
    "    train_y = y['label'].iloc[train_idx]\n",
    "    #print(train_x,train_y)\n",
    "    test_x = x[predictions].iloc[val_idx]\n",
    "    test_y = y['label'].iloc[val_idx]\n",
    "    lgb_model = Lgb_Classifier(train_x, train_y, test_x, test_y)\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_model.fit(train_x, train_y,eval_set=[(test_x, test_y)],verbose=100,early_stopping_rounds=50)\n",
    "    cbt_model = cbt.CatBoostClassifier()\n",
    "    cbt_model.fit(train_x, train_y,eval_set=[(test_x, test_y)],verbose=100,early_stopping_rounds=50)\n",
    "    len_col = train_x.shape[1]\n",
    "    nn_model = create_larger(len_col)\n",
    "    nn_model.fit(train_x, train_y, nb_epoch=20, batch_size=512,  verbose=2)\n",
    "\n",
    "    y_pred.extend(classify(np.array([lgb_model.predict(test_x), [n[1] for n in xgb_model.predict_proba(test_x)], \n",
    "                                    [n[1] for n in cbt_model.predict_proba(test_x)], nn_model.predict(test_x).T[0].tolist()]).sum(axis=0)/4))\n",
    "    y_true.extend(test_y)\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
